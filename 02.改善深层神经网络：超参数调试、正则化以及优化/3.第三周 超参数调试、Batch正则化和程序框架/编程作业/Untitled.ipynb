{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.framework import ops\n",
    "from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 12288\n",
      "number of test examples = 12288\n",
      "X_train shape: (1080, 12288)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 12288)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "# Flatten the training and test images\n",
    "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1)\n",
    "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1)\n",
    "# Normalize image vectors\n",
    "X_train = X_train_flatten/255.\n",
    "X_test = X_test_flatten/255.\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[1]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[1]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.4670 - accuracy: 0.1907\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.7581 - accuracy: 0.2528\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.6590 - accuracy: 0.2528\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.6189 - accuracy: 0.2657\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.6052 - accuracy: 0.2843\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.5450 - accuracy: 0.3509\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.5580 - accuracy: 0.3083\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.4834 - accuracy: 0.3824\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.4785 - accuracy: 0.3630\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.4685 - accuracy: 0.3648\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.4547 - accuracy: 0.3769\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.3965 - accuracy: 0.4065\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.3709 - accuracy: 0.4241\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.3663 - accuracy: 0.4250\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.3914 - accuracy: 0.4139\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.3718 - accuracy: 0.4250\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.2953 - accuracy: 0.4537\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.3142 - accuracy: 0.4546\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.3089 - accuracy: 0.4426\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.3076 - accuracy: 0.4602\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.2746 - accuracy: 0.4731\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.2602 - accuracy: 0.4565\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.2645 - accuracy: 0.4593\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.2403 - accuracy: 0.4935\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.2179 - accuracy: 0.4870\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.2307 - accuracy: 0.4750\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.1806 - accuracy: 0.5046\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.1745 - accuracy: 0.4898\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.1834 - accuracy: 0.4981\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.1771 - accuracy: 0.4926\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.1259 - accuracy: 0.5259\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.1394 - accuracy: 0.5241\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.1489 - accuracy: 0.5009\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.1131 - accuracy: 0.5361\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.1094 - accuracy: 0.5287\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.0782 - accuracy: 0.5407\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.0853 - accuracy: 0.5435\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.0847 - accuracy: 0.5491\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.0869 - accuracy: 0.5269\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.1065 - accuracy: 0.5343\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.1066 - accuracy: 0.5481\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.0412 - accuracy: 0.5944\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.0235 - accuracy: 0.5731\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.0195 - accuracy: 0.5898\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.0268 - accuracy: 0.5917\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.0346 - accuracy: 0.5815\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9951 - accuracy: 0.5954\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.9913 - accuracy: 0.6139\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.0254 - accuracy: 0.5796\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.0689 - accuracy: 0.5713\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 25)                307225    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 12)                312       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 6)                 78        \n",
      "=================================================================\n",
      "Total params: 307,615\n",
      "Trainable params: 307,615\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(25, activation = \"relu\"))\n",
    "model.add(layers.Dense(12, activation = \"relu\"))\n",
    "model.add(layers.Dense(6, activation=\"softmax\"))\n",
    "model.compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(X_train, Y_train, batch_size = 64, epochs = 50)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
